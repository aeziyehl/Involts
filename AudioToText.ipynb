{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aeziyehl/Involts/blob/main/AudioToText.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5hvo8QWN-a9"
      },
      "source": [
        "# üó£Ô∏è [**AudioToText**](https://github.com/Carleslc/AudioToText)\n",
        "\n",
        "[![Donate](https://www.ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/carleslc)\n",
        "\n",
        "### üõ† [Whisper by OpenAI](https://github.com/openai/whisper)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_lylR1xWMxk"
      },
      "source": [
        "## [Step 1] ‚öôÔ∏è Install the required libraries\n",
        "\n",
        "Click ‚ñ∂Ô∏è button below to install the dependencies for this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SJl7HJOeo0-P",
        "outputId": "6b059185-75e9-4444-f5ce-d8cb6767ff0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
            "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1.8/1.8 MB 29.3 MB/s eta 0:00:00\n",
            "Installing collected packages: pip\n",
            "Successfully installed pip-25.0.1\n",
            "Collecting git+https://github.com/openai/whisper.git@v20231117\n",
            "  Cloning https://github.com/openai/whisper.git (to revision v20231117) to /tmp/pip-req-build-95d5u7qs\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-95d5u7qs\n",
            "  Running command git checkout -q e58f28804528831904c3b6f2c0e473f346223433\n",
            "  Resolved https://github.com/openai/whisper.git to commit e58f28804528831904c3b6f2c0e473f346223433\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting openai==1.9.0\n",
            "  Downloading openai-1.9.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Collecting deepl\n",
            "  Downloading deepl-1.21.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting cohere\n",
            "  Downloading cohere-5.13.12-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting torch==2.1.0\n",
            "  Downloading torch-2.1.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting tensorflow-probability==0.23.0\n",
            "  Downloading tensorflow_probability-0.23.0-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Collecting typing-extensions==4.9.0\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.9.0) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.9.0) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.9.0) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.9.0) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai==1.9.0) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai==1.9.0) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.17.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.0)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.1.0 (from torch==2.1.0)\n",
            "  Downloading triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.23.0) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.23.0) (1.17.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.23.0) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.23.0) (3.1.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.23.0) (0.6.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.23.0) (0.1.9)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0) (12.5.82)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20231117) (0.61.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20231117) (10.6.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from deepl) (2.32.3)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
            "  Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting httpx-sse==0.4.0 (from cohere)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.27.2)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.21.0)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai==1.9.0) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.9.0) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.9.0) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.9.0) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.9.0) (0.7.0)\n",
            "INFO: pip is looking at multiple versions of pydantic to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pydantic<3,>=1.9.0 (from openai==1.9.0)\n",
            "  Downloading pydantic-2.10.5-py3-none-any.whl.metadata (30 kB)\n",
            "  Downloading pydantic-2.10.4-py3-none-any.whl.metadata (29 kB)\n",
            "  Downloading pydantic-2.10.3-py3-none-any.whl.metadata (172 kB)\n",
            "Collecting pydantic-core<3.0.0,>=2.18.2 (from cohere)\n",
            "  Downloading pydantic_core-2.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting pydantic<3,>=1.9.0 (from openai==1.9.0)\n",
            "  Downloading pydantic-2.10.2-py3-none-any.whl.metadata (170 kB)\n",
            "  Downloading pydantic-2.10.1-py3-none-any.whl.metadata (169 kB)\n",
            "  Downloading pydantic-2.10.0-py3-none-any.whl.metadata (167 kB)\n",
            "Collecting pydantic-core<3.0.0,>=2.18.2 (from cohere)\n",
            "  Downloading pydantic_core-2.27.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting pydantic<3,>=1.9.0 (from openai==1.9.0)\n",
            "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
            "Collecting pydantic-core<3.0.0,>=2.18.2 (from cohere)\n",
            "  Downloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->deepl) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->deepl) (2.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15->cohere) (0.28.1)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow-probability==0.23.0) (25.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow-probability==0.23.0) (1.17.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.0) (3.0.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20231117) (0.44.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20231117) (2024.11.6)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
            "Downloading openai-1.9.0-py3-none-any.whl (223 kB)\n",
            "Downloading torch-2.1.0-cp311-cp311-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_probability-0.23.0-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m118.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deepl-1.21.0-py3-none-any.whl (38 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading cohere-5.13.12-py3-none-any.whl (252 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "Downloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801416 sha256=995aadabce1a5af015e89c27e022094728eb84a8bfe1898c860e2b3076c548f4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-twzzi424/wheels/af/ef/7e/5a10cc0c75969cb9d9b7f4ab7fe606bccabad41b56749760e4\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: pydub, typing-extensions, types-requests, triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, httpx-sse, ffmpeg-python, fastavro, tiktoken, tensorflow-probability, pydantic-core, nvidia-cusolver-cu12, nvidia-cudnn-cu12, deepl, torch, pydantic, openai-whisper, openai, cohere\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.25.0\n",
            "    Uninstalling tensorflow-probability-0.25.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.25.0\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.27.2\n",
            "    Uninstalling pydantic_core-2.27.2:\n",
            "      Successfully uninstalled pydantic_core-2.27.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.6\n",
            "    Uninstalling pydantic-2.10.6:\n",
            "      Successfully uninstalled pydantic-2.10.6\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.61.1\n",
            "    Uninstalling openai-1.61.1:\n",
            "      Successfully uninstalled openai-1.61.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "altair 5.5.0 requires typing-extensions>=4.10.0; python_version < \"3.14\", but you have typing-extensions 4.9.0 which is incompatible.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.1.0 which is incompatible.\n",
            "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.1.0 which is incompatible.\n",
            "typeguard 4.4.1 requires typing-extensions>=4.10.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cohere-5.13.12 deepl-1.21.0 fastavro-1.10.0 ffmpeg-python-0.2.0 httpx-sse-0.4.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvtx-cu12-12.1.105 openai-1.9.0 openai-whisper-20231117 pydantic-2.9.2 pydantic-core-2.23.4 pydub-0.25.1 tensorflow-probability-0.23.0 tiktoken-0.9.0 torch-2.1.0 triton-2.1.0 types-requests-2.32.0.20241016 typing-extensions-4.9.0\n"
          ]
        }
      ],
      "source": [
        "#@title { display-mode: \"form\" }\n",
        "import subprocess\n",
        "\n",
        "from sys import platform as sys_platform\n",
        "\n",
        "status, ffmpeg_version = subprocess.getstatusoutput(\"ffmpeg -version\")\n",
        "\n",
        "if status != 0:\n",
        "  from platform import platform\n",
        "\n",
        "  if sys_platform == 'linux' and 'ubuntu' in platform().lower():\n",
        "    !apt install ffmpeg\n",
        "  else:\n",
        "    print(\"Install ffmpeg: https://ffmpeg.org/download.html\")\n",
        "else:\n",
        "  print(ffmpeg_version.split('\\n')[0])\n",
        "\n",
        "  NO_ROOT_WARNING = '|& grep -v \\\"WARNING: Running pip as the \\'root\\' user\"' # running in Colab\n",
        "\n",
        "  !pip install --no-warn-script-location --user --upgrade pip {NO_ROOT_WARNING}\n",
        "  !pip install --root-user-action=ignore git+https://github.com/openai/whisper.git@v20231117 openai==1.9.0 numpy scipy deepl pydub cohere ffmpeg-python torch==2.1.0 tensorflow-probability==0.23.0 typing-extensions==4.9.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A5bTMB8XmtI"
      },
      "source": [
        "## [Step 2] üìÅ Upload your audio files to the Files folder\n",
        "\n",
        "‚¨ÖÔ∏è Files folder in Google Colab is on the left menu\n",
        "\n",
        "Almost any audio or video file format is [supported](https://gist.github.com/Carleslc/1d6b922c8bf4a7e9627a6970d178b3a6)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS8OFGobrfJx"
      },
      "source": [
        "## [Step 2.5] üéô Record your own audio ‚è∫\n",
        "\n",
        "This is an **optional** step to record your microphone, useful if you do not have an audio file to upload and want to create one.\n",
        "\n",
        "Run this cell to start recording your microphone.\n",
        "A button will appear to stop the recording when you're done.\n",
        "\n",
        "The recording will be saved as `recording.wav` which you can use in the next step `audio_file`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwkH_QCu60qd"
      },
      "outputs": [],
      "source": [
        "# This cell code is a slightly modified version of DotCSV code in the following Colab along with other references:\n",
        "# https://colab.research.google.com/drive/1CvvYPAFemIZdSOt9fhN541esSlZR7Ic6?usp=sharing\n",
        "\n",
        "try:\n",
        "  import io\n",
        "  import ffmpeg\n",
        "  import numpy as np\n",
        "\n",
        "  # Only available in Google Colab\n",
        "  from google.colab.output import eval_js\n",
        "\n",
        "  from IPython.display import HTML, Audio\n",
        "  from scipy.io.wavfile import write, read as wav_read\n",
        "  from base64 import b64decode\n",
        "  from os.path import isfile\n",
        "\n",
        "  AUDIO_HTML = \"\"\"\n",
        "  <script>\n",
        "  var my_div = document.createElement(\"DIV\");\n",
        "  var my_p = document.createElement(\"P\");\n",
        "  var my_btn = document.createElement(\"BUTTON\");\n",
        "  var t = document.createTextNode(\"Starting recording...\");\n",
        "\n",
        "  my_btn.appendChild(t);\n",
        "  my_div.appendChild(my_btn);\n",
        "  document.body.appendChild(my_div);\n",
        "\n",
        "  var base64data = 0;\n",
        "  var reader;\n",
        "  var recorder, gumStream;\n",
        "  var recordButton = my_btn;\n",
        "\n",
        "  var handleSuccess = function(stream) {\n",
        "    gumStream = stream;\n",
        "    var options = {\n",
        "      bitsPerSecond: 16000,\n",
        "      mimeType : 'audio/webm;codecs=opus' //codecs=pcm\n",
        "    };\n",
        "    recorder = new MediaRecorder(stream, options);\n",
        "    //recorder = new MediaRecorder(stream);\n",
        "\n",
        "    recorder.ondataavailable = function(e) {\n",
        "      var url = URL.createObjectURL(e.data);\n",
        "      var preview = document.createElement('audio');\n",
        "      preview.controls = true;\n",
        "      preview.src = url;\n",
        "      document.body.appendChild(preview);\n",
        "\n",
        "      reader = new FileReader();\n",
        "      reader.readAsDataURL(e.data);\n",
        "      reader.onloadend = function() {\n",
        "        base64data = reader.result;\n",
        "        //console.log(\"reader.onloadend: \" + base64data);\n",
        "      }\n",
        "    };\n",
        "    recorder.start();\n",
        "    recordButton.innerText = \"üî¥ Recording... press to STOP\";\n",
        "  };\n",
        "\n",
        "  navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "  function toggleRecording() {\n",
        "    if (recorder && recorder.state == \"recording\") {\n",
        "        recorder.stop();\n",
        "        gumStream.getAudioTracks()[0].stop();\n",
        "        recordButton.innerText = \"Saving the recording... please wait!\";\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // https://stackoverflow.com/a/951057\n",
        "  function sleep(ms) {\n",
        "    return new Promise(resolve => setTimeout(resolve, ms));\n",
        "  }\n",
        "\n",
        "  var data = new Promise(resolve => {\n",
        "    recordButton.onclick = () => {\n",
        "      toggleRecording();\n",
        "\n",
        "      sleep(2000).then(() => {\n",
        "        // wait 2000ms for the data to be available...\n",
        "        //console.log(\"resolve data: \" + base64data);\n",
        "        resolve(base64data.toString());\n",
        "      });\n",
        "    }\n",
        "  });\n",
        "\n",
        "  function doneRecording(recording_file) {\n",
        "    my_div.removeChild(recordButton);\n",
        "    my_p.innerText = recording_file;\n",
        "    my_div.appendChild(my_p);\n",
        "  }\n",
        "\n",
        "  </script>\n",
        "  \"\"\"\n",
        "\n",
        "  def get_audio():\n",
        "    display(HTML(AUDIO_HTML))\n",
        "    data = eval_js(\"data\")\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "\n",
        "    process = (ffmpeg\n",
        "      .input('pipe:0')\n",
        "      .output('pipe:1', format='wav')\n",
        "      .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "    )\n",
        "    output, err = process.communicate(input=binary)\n",
        "\n",
        "    riff_chunk_size = len(output) - 8\n",
        "    # Break up the chunk size into four bytes, held in b.\n",
        "    q = riff_chunk_size\n",
        "    b = []\n",
        "    for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "    # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "    riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "    sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "    return audio, sr\n",
        "\n",
        "  recording_file = \"\" #@param {type:\"string\"}\n",
        "\n",
        "  if isfile(recording_file):\n",
        "    print(f\"{recording_file} already exists, if you want to create another recording with the same name, delete it first\")\n",
        "  else:\n",
        "    # record microphone\n",
        "    audio, sr = get_audio()\n",
        "\n",
        "    # write recording\n",
        "    write(recording_file, sr, audio)\n",
        "\n",
        "    eval_js(f'doneRecording(\"{recording_file}\")')\n",
        "except ImportError:\n",
        "  print(\"Recording only available in Google Colab\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9_I0W3tqTjr"
      },
      "source": [
        "## [Step 3] üëÇ Transcribe or Translate\n",
        "\n",
        "3.1. Choose a `task`:\n",
        "  - `Transcribe` speech to text in the same language of the source audio file.\n",
        "  - `Translate to English` speech to text in English.\n",
        "  \n",
        "Translation to other languages is not supported with _Whisper_ by default.\n",
        "You may try to choose the _Transcribe_ task and set your desired `language`, but translation is not guaranteed. However, you can use **_DeepL_** later in the Step 5 to translate the transcription to another language.\n",
        "\n",
        "3.2. Edit the `audio_file` to match your uploaded file name to transcribe.\n",
        "\n",
        "- If you want to transcribe multiple files with the same parameters you must separate their file names with commas `,`\n",
        "\n",
        "3.3. Run this cell and wait for the transcription to complete.\n",
        "\n",
        "  You can try other parameters if the result with default parameters does not suit your needs.\n",
        "\n",
        "  [Available models and languages](https://github.com/openai/whisper#available-models-and-languages)\n",
        "\n",
        "  Setting the `language` to the language of source audio file may provide better results than Auto-Detect.\n",
        "\n",
        "  You can add an optional initial `prompt` to provide context about the audio or encourage a specific writing style, see the [prompting guide](https://platform.openai.com/docs/guides/speech-to-text/prompting).\n",
        "\n",
        "  If the execution takes too long to complete you can choose a smaller model in `use_model`, with an accuracy tradeoff, or use the OpenAI API.\n",
        "\n",
        "  By default the open-source models are used, but you can also use the OpenAI API if the `api_key` parameter is set with your [OpenAI API Key](https://platform.openai.com/account/api-keys), which can improve the inference speed substantially, but it has an associated cost, see [API pricing](https://openai.com/pricing#audio-models).\n",
        "\n",
        "  When using API some options are fixed: **use_model** is ignored (uses _large-v2_) and **coherence_preference** is ignored (uses _More coherence_).\n",
        "  \n",
        "  More parameters are available in the code `options` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "opNkn_Lgpat4",
        "outputId": "b9951b44-58d6-439e-f99f-b7f9f0388824",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU\n",
            "GPU 0: Tesla T4 (UUID: GPU-3b195694-d7d3-4a4a-5551-ef5193c26b72)\n",
            "\n",
            "Loading large-v2 model... /root/.cache/whisper/large-v2.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.87G/2.87G [01:01<00:00, 49.9MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model large-v2 is multilingual and has 1,541,384,960 parameters.\n",
            "\n",
            "-- TRANSCRIPTION --\n",
            "\n",
            "Processing: Fidel Bas 1.m4a\n",
            "\n",
            "Detected language: Tagalog\n",
            "\n",
            "[00:00.000 --> 00:09.000]  Can you describe any family conflicts you have experienced at home?\n",
            "[00:09.000 --> 00:16.000]  Sometimes miscommunication. Hindi kami mag-communicate tungkol sa cellphone.\n",
            "[00:16.000 --> 00:21.000]  Hindi kami makipagbanding sa mga family.\n",
            "[00:21.000 --> 00:37.000]  How do these family conflicts make you feel in school?\n",
            "[00:37.000 --> 00:53.000]  Sometimes I can feel lonely. Hindi kami mag-communicate sa mga family.\n",
            "[00:53.000 --> 01:06.000]  How type of family conflicts affects you the most and why?\n",
            "[01:06.000 --> 01:16.000]  Financial. Pwede. Kailangan nang in-need mo mga materials.\n",
            "[01:16.000 --> 01:24.000]  May problema rin ang financial kasi magkuhangan ang kwarta para sa pagpalit.\n",
            "[01:24.000 --> 01:31.000]  Hindi enough siya ba? Hindi na kumakuha akong need o ganahan.\n",
            "[01:32.000 --> 01:47.000]  How do family conflicts influence your ability to focus or participate in class activities?\n",
            "[01:47.000 --> 01:58.000]  Influence ako from motivating myself to be with others like that.\n",
            "[01:58.000 --> 02:08.000]  Kikomunicate ko more sa mga school, mga classmate, uba pang mga grade and sections.\n",
            "[02:08.000 --> 02:15.000]  Ma-influence ako na stand up ko sa galing mo.\n",
            "[02:16.000 --> 02:32.000]  Can you share an experience where family problems affected your performance in school?\n",
            "[02:32.000 --> 02:48.000]  First, experience na ako itong sabahan ko at magnabuhat, magmalik mo, magnadepress ko ba.\n",
            "[02:48.000 --> 02:51.000]  Hindi na kayo kagustuhan mo school na ito.\n",
            "[02:51.000 --> 02:58.000]  Tungkol kayo itong nakasala ko sa akong mama ba na bate.\n",
            "[02:59.000 --> 03:04.000]  How do you manage your school work when dealing with family conflicts?\n",
            "[03:06.000 --> 03:09.000]  Manage na ako by time management.\n",
            "[03:09.000 --> 03:13.000]  Hindi kasi sa kayo magfocus sa problema sa pamilya.\n",
            "[03:13.000 --> 03:16.000]  Focus ako sa school.\n",
            "[03:16.000 --> 03:21.000]  Pag kayo mag-dool nila, kikomunicate pa, di ko maigot ba.\n",
            "[03:22.000 --> 03:30.000]  So, magkuhansa ako time alone o galingan para magbuhat sa mga assignment o do fun activities.\n",
            "[03:31.000 --> 03:39.000]  How do you think your teachers and school staff perceive your behavior when you are going through family issues?\n",
            "[03:40.000 --> 03:42.000]  What I think?\n",
            "[03:43.000 --> 03:48.000]  Murag kuhansa na ako mag-worried.\n",
            "[03:48.000 --> 03:54.000]  Dara pa sa school, sabahan mo kayo dara sa classroom naman.\n",
            "[03:55.000 --> 03:57.000]  Assignments behaving kayo.\n",
            "[03:57.000 --> 03:59.000]  Sabahan during classes.\n",
            "[04:00.000 --> 04:03.000]  Kikita sila na ako na murag hilom-hilom.\n",
            "[04:03.000 --> 04:07.000]  May ngayon din na sila na may something wrong na ako.\n",
            "[04:08.000 --> 04:13.000]  Have any teachers or school staff supported you during difficult times at home?\n",
            "[04:13.000 --> 04:16.000]  If yes, how did they help you?\n",
            "[04:20.000 --> 04:21.000]  Yes.\n",
            "[04:22.000 --> 04:23.000]  Ni Ma'am Chiara.\n",
            "[04:24.000 --> 04:27.000]  Nakuha yung problema nang nangyaris ko balay.\n",
            "[04:28.000 --> 04:31.000]  Nasakitan ko sa mga mga tubak. Sabahan pa ito.\n",
            "[04:32.000 --> 04:34.000]  Murag ni-speak up ko.\n",
            "[04:34.000 --> 04:37.000]  I-support ko ni Ma'am Chiara with all the motivation.\n",
            "[04:37.000 --> 04:40.000]  Sana iyong mastorya na pang-guidance.\n",
            "[04:42.000 --> 04:46.000]  How do family problems make it hard for you to do well in school?\n",
            "[04:48.000 --> 04:51.000]  It's hard for me kay di ko kaka-focus ba.\n",
            "[04:51.000 --> 04:54.000]  Murag mag-focus ko more sa akong family.\n",
            "[04:55.000 --> 04:58.000]  Sa school, murag di kayo kaka-focus kayo.\n",
            "[04:58.000 --> 05:00.000]  Family may mas important.\n",
            "[05:02.000 --> 05:05.000]  Murag mag-focus po umayos ako sa family.\n",
            "[05:05.000 --> 05:09.000]  Sa problems, try ko find a way to fix it.\n",
            "[05:11.000 --> 05:15.000]  How do these family conflicts make you feel at home?\n",
            "[05:18.000 --> 05:19.000]  Again.\n",
            "[05:19.000 --> 05:23.000]  How do these family conflicts make you feel at home?\n",
            "[05:25.000 --> 05:27.000]  Murag ma-influence ko ba.\n",
            "[05:27.000 --> 05:32.000]  Family conflicts, murag mo-reflect sa akong nauna na\n",
            "[05:32.000 --> 05:34.000]  ang anidyo di ko no.\n",
            "[05:34.000 --> 05:40.000]  Murag mo-feel at home ko tungod sa lahat na akong naagian ba.\n",
            "[05:40.000 --> 05:43.000]  So, murag kung ginawa ko sa sagasa,\n",
            "[05:43.000 --> 05:45.000]  kinumdam ko sa family conflicts.\n",
            "[05:45.000 --> 05:48.000]  So, murag mo-feel na ako naraja ko sa balay.\n",
            "[05:49.000 --> 05:50.000]  Thank you.\n",
            "[05:54.000 --> 05:55.000]  Thank you.\n",
            "\n",
            "Processing: Fidel Bas 2.m4a\n",
            "\n",
            "Detected language: Tagalog\n",
            "\n",
            "[00:00.000 --> 00:06.000]  Can you describe any family conflicts you have experienced at home?\n",
            "[00:06.000 --> 00:10.000]  Mga misunderstanding fights.\n",
            "[00:10.000 --> 00:17.000]  Mga joke-joke na nagkapikunan.\n",
            "[00:17.000 --> 00:22.000]  How do these family conflicts make you feel in school?\n",
            "[00:22.000 --> 00:26.000]  A little different.\n",
            "[00:26.000 --> 00:31.000]  Matromagamay.\n",
            "[00:31.000 --> 00:34.000]  Hindi nakaganahan mo buhat mo.\n",
            "[00:34.000 --> 00:40.000]  Change mo personality sa school.\n",
            "[00:40.000 --> 00:45.000]  What type of family conflicts affects you the most and why?\n",
            "[00:45.000 --> 00:49.000]  Favoritism.\n",
            "[00:49.000 --> 00:52.000]  Hindi siya fair.\n",
            "[00:52.000 --> 01:04.000]  How do these family conflicts influence your ability to focus or participate in class activities?\n",
            "[01:04.000 --> 01:10.000]  Hindi lang kasi maka-affect pero maka-affect din siya gamay.\n",
            "[01:10.000 --> 01:14.000]  Base ko sa mga decisions based on experience niya.\n",
            "[01:14.000 --> 01:19.000]  Maka-experience kayo natin. Makahimot siya sa mga bating decisions.\n",
            "[01:20.000 --> 01:25.000]  Can you share an experience where family problems affected your performance in school?\n",
            "[01:25.000 --> 01:31.000]  Ikaw kanina mga sige o mga nai-ikaw ba?\n",
            "[01:31.000 --> 01:35.000]  Mga taghan o baton niya.\n",
            "[01:35.000 --> 01:37.000]  Mayaw-yawan niya.\n",
            "[01:37.000 --> 01:40.000]  Kasi tungod sa kanina mga conflict niya na ikaw.\n",
            "[01:40.000 --> 01:42.000]  Walang nangabuha ito mga ikaw.\n",
            "[01:42.000 --> 01:44.000]  Ang iba to nun para sa school.\n",
            "[01:45.000 --> 01:50.000]  How do you manage your school work when dealing with family conflicts?\n",
            "[01:50.000 --> 01:53.000]  Time management mostly kayo.\n",
            "[01:53.000 --> 01:56.000]  Huwag ka humano masabahan kayo.\n",
            "[01:56.000 --> 01:58.000]  Mga dapat ko ang dayo.\n",
            "[01:58.000 --> 02:02.000]  Para makabuha dyan ang mga iba to nun sa kanina para sa school na kanina.\n",
            "[02:04.000 --> 02:11.000]  How do you think your teachers and school staff perceive your behavior when you are going through family issues?\n",
            "[02:12.000 --> 02:16.000]  Hindi rin okay siya.\n",
            "[02:16.000 --> 02:18.000]  Hindi rin maganda kayo siya.\n",
            "[02:18.000 --> 02:19.000]  Bantayan siya sa mga kanina.\n",
            "[02:19.000 --> 02:21.000]  Huwag mo change siya sa mga acts.\n",
            "[02:21.000 --> 02:22.000]  Pero mostly kayo.\n",
            "[02:22.000 --> 02:23.000]  Makakakawin ko.\n",
            "[02:23.000 --> 02:25.000]  Basta makakakawin nga.\n",
            "[02:25.000 --> 02:27.000]  May magandang conflict kayo.\n",
            "[02:27.000 --> 02:28.000]  Wag mo makasala.\n",
            "[02:28.000 --> 02:29.000]  Kasi tungod sa kanina.\n",
            "[02:29.000 --> 02:31.000]  Mga conflict nga nagandang.\n",
            "[02:33.000 --> 02:38.000]  Have any teachers or school staff supported you during difficult times at home?\n",
            "[02:38.000 --> 02:40.000]  If yes, how did they help you?\n",
            "[02:40.000 --> 02:41.000]  Wala.\n",
            "[02:41.000 --> 02:42.000]  Wala ba kayo.\n",
            "[02:42.000 --> 02:48.000]  May mga makakawin ako sa mga conflicts.\n",
            "[02:52.000 --> 02:56.000]  How do family problems make it hard for you to do well in school?\n",
            "[02:56.000 --> 02:59.000]  Maka-affect siya ako mentally.\n",
            "[03:01.000 --> 03:06.000]  Maraming ma-activated ka bakit tungod sa conflict.\n",
            "[03:07.000 --> 03:09.000]  Maka-affect siya ako mentally.\n",
            "[03:10.000 --> 03:11.000]  Physically.\n",
            "[03:12.000 --> 03:13.000]  Wala na igana mo.\n",
            "[03:13.000 --> 03:15.000]  Bawat sa mga bato mo.\n",
            "[03:17.000 --> 03:20.000]  How do these family conflicts make you feel at home?\n",
            "[03:24.000 --> 03:26.000]  Wala na igana mo.\n",
            "[03:26.000 --> 03:27.000]  Balihok kayo sa balay.\n",
            "[03:29.000 --> 03:30.000]  Maka-feel kayo.\n",
            "[03:30.000 --> 03:31.000]  Lazyness.\n",
            "[03:31.000 --> 03:32.000]  Conflict nga.\n",
            "[03:32.000 --> 03:34.000]  May tabo sa family.\n",
            "[03:36.000 --> 03:37.000]  Thank you.\n",
            "\n",
            "Processing: Fidel Bas 3.m4a\n",
            "\n",
            "Detected language: Tagalog\n",
            "\n",
            "[00:00.000 --> 00:06.000]  Can you describe any family conflicts you have experienced at home?\n",
            "[00:08.000 --> 00:10.000]  Misunderstanding.\n",
            "[00:14.000 --> 00:21.000]  Misunderstanding kay kanaganing especially with my siblings.\n",
            "[00:21.000 --> 00:26.000]  Kaya if ngay ganaan nang usta niya, ganaan siya nang usta niya, usta rin na ah.\n",
            "[00:26.000 --> 00:28.000]  So may mag-away me.\n",
            "[00:30.000 --> 00:34.000]  How do these family conflicts make you feel in school?\n",
            "[00:39.000 --> 00:41.000]  Wala ra.\n",
            "[00:43.000 --> 00:48.000]  What type of family conflicts affects you the most and why?\n",
            "[00:55.000 --> 00:57.000]  Misunderstanding d'yun.\n",
            "[00:57.000 --> 00:59.000]  Kay...\n",
            "[01:01.000 --> 01:05.000]  Kay lahi ba yung generation sa akong parents niya?\n",
            "[01:05.000 --> 01:08.000]  Aside kay dili d'yun mag-sinabot ba niya?\n",
            "[01:08.000 --> 01:11.000]  Kanang mas mapili sila sa ilang side, inga na inga na.\n",
            "[01:13.000 --> 01:19.000]  How do family conflicts influence your ability to focus or participate in class activities?\n",
            "[01:28.000 --> 01:35.000]  How do family conflicts influence your ability to focus or participate in class activities?\n",
            "[01:35.000 --> 01:37.000]  Kaan?\n",
            "[01:41.000 --> 01:43.000]  Sometimes kay...\n",
            "[01:43.000 --> 01:45.000]  Murag...\n",
            "[01:45.000 --> 01:47.000]  Murag dawaton lang suna ko ba nga.\n",
            "[01:47.000 --> 01:52.000]  Inga na d'yun ang mga tao, nga lahi-lahi d'yun ang... lahi-lahi d'yun ta ba?\n",
            "[01:53.000 --> 01:55.000]  Nga.\n",
            "[01:55.000 --> 01:57.000]  Labi na sa nga rin sa school nga.\n",
            "[01:57.000 --> 01:59.000]  Dili ba ni mo sila ka-dugo or inga na.\n",
            "[01:59.000 --> 02:01.000]  Hindi mo sila...\n",
            "[02:01.000 --> 02:03.000]  Ma-ingan nga family pero...\n",
            "[02:03.000 --> 02:05.000]  Dapat kang masabot.\n",
            "[02:05.000 --> 02:07.000]  Sa...\n",
            "[02:08.000 --> 02:13.000]  Can you share an experience where family problems affected your performance in school?\n",
            "[02:16.000 --> 02:18.000]  Sometimes kay...\n",
            "[02:18.000 --> 02:20.000]  If na ay...\n",
            "[02:20.000 --> 02:22.000]  Makuhan...\n",
            "[02:22.000 --> 02:24.000]  Sabi akong classmate kay makuhan siya nga...\n",
            "[02:24.000 --> 02:25.000]  Kanang...\n",
            "[02:25.000 --> 02:27.000]  Nasa'y...\n",
            "[02:27.000 --> 02:28.000]  Opinyon niya.\n",
            "[02:28.000 --> 02:29.000]  Murakog kong...\n",
            "[02:29.000 --> 02:31.000]  Hindi ko ganan sa iyang opinyon kay...\n",
            "[02:31.000 --> 02:33.000]  Murag makakos o...\n",
            "[02:33.000 --> 02:34.000]  Argument.\n",
            "[02:34.000 --> 02:36.000]  Inga na ba?\n",
            "[02:36.000 --> 02:40.000]  How do you manage your schoolwork when dealing with family conflicts?\n",
            "[02:41.000 --> 02:43.000]  Umm...\n",
            "[02:43.000 --> 02:44.000]  Modistans ko nila.\n",
            "[02:44.000 --> 02:45.000]  Sa balay.\n",
            "[02:45.000 --> 02:47.000]  Like mo-stay ko sa akong room.\n",
            "[02:47.000 --> 02:48.000]  For...\n",
            "[02:48.000 --> 02:49.000]  Pila ka...\n",
            "[02:49.000 --> 02:51.000]  Minutes or hours para...\n",
            "[02:51.000 --> 02:53.000]  Maulian para ma...\n",
            "[02:53.000 --> 02:55.000]  Take ka akong mind off of it.\n",
            "[02:57.000 --> 03:03.000]  How do you think your teachers and school staff perceive your behavior when you are going through family issues?\n",
            "[03:04.000 --> 03:05.000]  Umm...\n",
            "[03:05.000 --> 03:07.000]  Ang uban teachers kay...\n",
            "[03:08.000 --> 03:11.000]  Ang uban teachers kay makabantay dito sila nga...\n",
            "[03:11.000 --> 03:13.000]  Na inga na ang problema ng...\n",
            "[03:13.000 --> 03:14.000]  Usa ka student pero...\n",
            "[03:14.000 --> 03:16.000]  Pala ang uban nga makabantay pero...\n",
            "[03:16.000 --> 03:18.000]  Ibaliwala ra kay...\n",
            "[03:18.000 --> 03:20.000]  Feeler nila nga...\n",
            "[03:20.000 --> 03:21.000]  Kanang...\n",
            "[03:21.000 --> 03:22.000]  Okay.\n",
            "[03:22.000 --> 03:23.000]  Kanang...\n",
            "[03:23.000 --> 03:24.000]  Ma-pasture na siya.\n",
            "[03:24.000 --> 03:25.000]  Nga...\n",
            "[03:25.000 --> 03:26.000]  Ang...\n",
            "[03:26.000 --> 03:27.000]  Nga ang time kay...\n",
            "[03:27.000 --> 03:28.000]  Kanang...\n",
            "[03:28.000 --> 03:29.000]  Kanang maagir na siya.\n",
            "[03:29.000 --> 03:30.000]  Inga na.\n",
            "[03:32.000 --> 03:38.000]  Have any teachers or school staff supported you during difficult times at home?\n",
            "[03:38.000 --> 03:40.000]  If yes, then how did they help you?\n",
            "[03:41.000 --> 03:43.000]  Yes kay...\n",
            "[03:44.000 --> 03:46.000]  Na ako yung usa ka teacher pa.\n",
            "[03:46.000 --> 03:47.000]  Grade 6 niya.\n",
            "[03:47.000 --> 03:48.000]  Kanang...\n",
            "[03:48.000 --> 03:50.000]  Advisor to na ko siya niya.\n",
            "[03:50.000 --> 03:51.000]  Nang utana siya na ko nga...\n",
            "[03:51.000 --> 03:53.000]  Gano daw ko mo to...\n",
            "[03:53.000 --> 03:54.000]  Ni...\n",
            "[03:54.000 --> 03:55.000]  Ni open up ko niya sa tanan.\n",
            "[03:55.000 --> 03:56.000]  Then...\n",
            "[03:57.000 --> 03:58.000]  Then...\n",
            "[03:58.000 --> 03:59.000]  Wala siya nitabang na ko...\n",
            "[03:59.000 --> 04:00.000]  Umm...\n",
            "[04:00.000 --> 04:02.000]  Ay, nitabang siya na ko physically and mentally.\n",
            "[04:04.000 --> 04:08.000]  How do family problems make it hard for you to do well in school?\n",
            "[04:11.000 --> 04:12.000]  Umm...\n",
            "[04:15.000 --> 04:17.000]  Dili mang guru...\n",
            "[04:17.000 --> 04:19.000]  Dili mang guru siya makakuan.\n",
            "[04:19.000 --> 04:21.000]  Bro, dili siya...\n",
            "[04:21.000 --> 04:24.000]  Dili siya maka-affect na ko sa school.\n",
            "[04:24.000 --> 04:25.000]  Bro, like, mentally, oh.\n",
            "[04:25.000 --> 04:27.000]  Maka-affect siya na ko mentally.\n",
            "[04:27.000 --> 04:31.000]  How do these family conflicts make you feel at home?\n",
            "[04:35.000 --> 04:36.000]  Kanang...\n",
            "[04:36.000 --> 04:37.000]  Weird kayo.\n",
            "[04:37.000 --> 04:38.000]  Kay...\n",
            "[04:38.000 --> 04:40.000]  Dabi na anong...\n",
            "[04:40.000 --> 04:41.000]  Kanang...\n",
            "[04:41.000 --> 04:42.000]  Makaingon ka, nga...\n",
            "[04:43.000 --> 04:44.000]  Favoritism...\n",
            "[04:44.000 --> 04:45.000]  Bisag dili...\n",
            "[04:45.000 --> 04:47.000]  Bisag mas kuha nang...\n",
            "[04:47.000 --> 04:50.000]  Bisag mas kailangan lang ang time akong mga manghod.\n",
            "[04:50.000 --> 04:51.000]  Ya.\n",
            "[04:51.000 --> 04:52.000]  Dabi na karoon nga...\n",
            "[04:52.000 --> 04:53.000]  Akong mga manghod...\n",
            "[04:53.000 --> 04:55.000]  Kay mga puro lalaki.\n",
            "[04:56.000 --> 04:57.000]  Great work.\n",
            "[04:57.000 --> 04:58.000]  Thank you.\n",
            "\n",
            "Processing: Fidel Bas 4.m4a\n",
            "\n",
            "Detected language: Tagalog\n",
            "\n",
            "[00:00.000 --> 00:05.000]  Can you describe any family conflicts you have experienced at home?\n",
            "[00:05.000 --> 00:15.000]  Okay, so for instance, one of the main conflicts that I've experienced in my home is about financial stability of both of my parents.\n",
            "[00:15.000 --> 00:25.000]  Because I'm diligent with my parents but that's why we struggle with budgeting our money.\n",
            "[00:25.000 --> 00:31.000]  Especially, we don't have time to talk to each other because I really like my mom and I really like my dad.\n",
            "[00:31.000 --> 00:39.000]  So there are times that I need to talk to my dad but we don't have time to talk.\n",
            "[00:39.000 --> 00:45.000]  That's why some simple misunderstandings turn into arguments.\n",
            "[00:45.000 --> 00:49.000]  So that is one of the most common conflicts that I've experienced.\n",
            "[00:49.000 --> 00:53.000]  How do these family conflicts make you feel in school?\n",
            "[00:53.000 --> 00:57.000]  As human as we are, of course, it would make me feel sad and miserable.\n",
            "[00:57.000 --> 01:04.000]  Because they always fight and of course, I get sick because I can't carry anything.\n",
            "[01:04.000 --> 01:13.000]  I work as a student and I feel guilty because I can't carry anything.\n",
            "[01:13.000 --> 01:18.000]  The least I can carry is to study and finish school.\n",
            "[01:18.000 --> 01:22.000]  So I feel guilty and sad because I can't carry anything.\n",
            "[01:22.000 --> 01:27.000]  What type of family conflict affects you the most and why?\n",
            "[01:27.000 --> 01:33.000]  I think the most family conflict that affects me is that they always fight.\n",
            "[01:33.000 --> 01:36.000]  So regarding the financial problems that I stated earlier,\n",
            "[01:36.000 --> 01:40.000]  the other thing is that they don't subdivide each other.\n",
            "[01:40.000 --> 01:44.000]  For example, I don't answer to their questions.\n",
            "[01:44.000 --> 01:51.000]  And then, my father and mother blame me for what I did.\n",
            "[01:51.000 --> 01:53.000]  So of course, they have a lot on both sides.\n",
            "[01:53.000 --> 01:55.000]  It's like they have a lot of egos.\n",
            "[01:55.000 --> 01:59.000]  They blame each other for what I did.\n",
            "[01:59.000 --> 02:01.000]  They blame each other.\n",
            "[02:01.000 --> 02:06.000]  It's like a simple misunderstanding turns out into an argument.\n",
            "[02:06.000 --> 02:08.000]  That's why they fight.\n",
            "[02:08.000 --> 02:14.000]  And of course, it affects me because it distracts me from their fight.\n",
            "[02:15.000 --> 02:21.000]  How did this family conflict influence your ability to focus or participate in class activities?\n",
            "[02:21.000 --> 02:24.000]  So regarding my relationship with my mother,\n",
            "[02:24.000 --> 02:26.000]  because it affects her,\n",
            "[02:26.000 --> 02:31.000]  it has a negative influence on my ability to go to school because it always distracts me.\n",
            "[02:31.000 --> 02:36.000]  My thoughts are more focused on my problems at home.\n",
            "[02:36.000 --> 02:39.000]  And then, I don't have any worries.\n",
            "[02:39.000 --> 02:44.000]  I'm very absent-minded in class.\n",
            "[02:44.000 --> 02:51.000]  That's why it has a negative effect because it decreases my performance lately in class\n",
            "[02:51.000 --> 02:56.000]  since I dwell much more on my problems at home.\n",
            "[02:57.000 --> 03:02.000]  Can you share an experience where family problems affected your performance in school?\n",
            "[03:02.000 --> 03:04.000]  So regarding that,\n",
            "[03:04.000 --> 03:09.000]  when we had a performance test in math,\n",
            "[03:09.000 --> 03:11.000]  I had a breakdown.\n",
            "[03:11.000 --> 03:19.000]  That was my last straw because I didn't have any groupmates to support me.\n",
            "[03:19.000 --> 03:21.000]  And then, it was timing.\n",
            "[03:21.000 --> 03:25.000]  My parents were worried because I didn't have anyone to support me.\n",
            "[03:25.000 --> 03:28.000]  That's why I was the first one to take the performance test.\n",
            "[03:28.000 --> 03:33.000]  But then, it affected me because I didn't pass the math test.\n",
            "[03:33.000 --> 03:37.000]  And then, I got a deducted score which is very bad.\n",
            "[03:37.000 --> 03:43.000]  So of course, this result affected me because I neglected my activities.\n",
            "[03:43.000 --> 03:50.000]  I neglected my activities because they didn't realize my struggles during the process.\n",
            "[03:50.000 --> 03:54.000]  So this affected me in a way that I detected my score,\n",
            "[03:54.000 --> 03:58.000]  that I didn't pass, and then, I got a deducted grade.\n",
            "[03:59.000 --> 04:03.000]  How do you manage your schoolwork when dealing with family conflicts?\n",
            "[04:03.000 --> 04:10.000]  So to manage, I only have at least two possible ways.\n",
            "[04:10.000 --> 04:13.000]  First is to, I mean, two or three.\n",
            "[04:13.000 --> 04:17.000]  So first is, you separate first.\n",
            "[04:17.000 --> 04:23.000]  You segregate what you need to do and what you want to do.\n",
            "[04:23.000 --> 04:32.000]  Because in this way, at least, you realize what you need to do and what you can leave for another day.\n",
            "[04:32.000 --> 04:37.000]  And the next thing is, to manage schoolwork when you have problems,\n",
            "[04:37.000 --> 04:39.000]  is to always seek for help.\n",
            "[04:39.000 --> 04:43.000]  Because of course, it's not that we can do it by ourselves.\n",
            "[04:43.000 --> 04:47.000]  Because it's very difficult.\n",
            "[04:47.000 --> 04:49.000]  And we are just only humans who need help.\n",
            "[04:49.000 --> 04:58.000]  So that's my first and second main structure, main function to manage,\n",
            "[04:58.000 --> 05:04.000]  is to segregate, to differentiate what needs to be done.\n",
            "[05:04.000 --> 05:12.000]  And to always seek for help and never lose hope.\n",
            "[05:12.000 --> 05:16.000]  Because if you lose hope, if you let go of your body food,\n",
            "[05:16.000 --> 05:19.000]  wherever your foundation is to continue your work.\n",
            "[05:19.000 --> 05:21.000]  So yeah, that's my main structure.\n",
            "[05:21.000 --> 05:27.000]  How do you think your teachers and school staff perceive your behavior when you are going through a family issue?\n",
            "[05:28.000 --> 05:29.000]  So...\n",
            "[05:29.000 --> 05:31.000]  Can I go back?\n",
            "[05:31.000 --> 05:37.000]  How do you think your teachers and school staff perceive your behavior when you are going through a family issue?\n",
            "[05:37.000 --> 05:40.000]  So, one of the things that I've observed here in Divino,\n",
            "[05:40.000 --> 05:45.000]  is that their staff and teachers are easy to be monitored when someone is struggling.\n",
            "[05:45.000 --> 05:57.000]  Maybe because they are in a state where they are not okay.\n",
            "[05:57.000 --> 06:02.000]  And then, since the observance of the teachers is not good,\n",
            "[06:02.000 --> 06:05.000]  like they can see that the child is walking.\n",
            "[06:05.000 --> 06:10.000]  So that's why they go there and will ask if it's okay.\n",
            "[06:10.000 --> 06:14.000]  And if it's okay, like they don't want the other student,\n",
            "[06:14.000 --> 06:17.000]  because you are occupied in the discussion.\n",
            "[06:17.000 --> 06:20.000]  Of course, they are concerned because part of their job as a teacher,\n",
            "[06:20.000 --> 06:23.000]  because they are the second parents of the school.\n",
            "[06:24.000 --> 06:29.000]  Have any teachers or school staff supported you during your difficult times at home?\n",
            "[06:29.000 --> 06:31.000]  If yes, how did they help you?\n",
            "[06:32.000 --> 06:34.000]  Well, I can't really specify who they are,\n",
            "[06:34.000 --> 06:37.000]  but yes, during the night time of my event,\n",
            "[06:37.000 --> 06:43.000]  because I can't do it because I was overwhelmed with the emotions that I've been feeling lately.\n",
            "[06:43.000 --> 06:48.000]  And then, they helped me by telling me first to just calm down.\n",
            "[06:48.000 --> 06:52.000]  Don't rush things because it will always go by.\n",
            "[06:52.000 --> 06:57.000]  Because these problems are just a starting point for us to realize that\n",
            "[06:57.000 --> 07:00.000]  maybe we can unlock our full potential through these problems and difficulties.\n",
            "[07:00.000 --> 07:04.000]  So therefore, I reflected on what they said,\n",
            "[07:04.000 --> 07:08.000]  that maybe this is the only way to accept these problems and difficulties.\n",
            "[07:08.000 --> 07:12.000]  Even though how hard it is, we never know that it will help us in the future.\n",
            "[07:12.000 --> 07:19.000]  Because no matter what happens, we will be able to experience the problems.\n",
            "[07:19.000 --> 07:22.000]  And then, we will be able to fight because we've been through this.\n",
            "[07:22.000 --> 07:31.000]  So that's when I realized that it doesn't mean that the problems that I faced are the end of my life.\n",
            "[07:31.000 --> 07:36.000]  It maybe means that it is the starting point of your experience.\n",
            "[07:37.000 --> 07:42.000]  How do family problems make it hard for you to do well in school?\n",
            "[07:43.000 --> 07:50.000]  Well, based on my experience and also the experience that I've seen from my fellow friends and peers,\n",
            "[07:50.000 --> 07:57.000]  family problems can affect you a lot in a way that is emotional, physical,\n",
            "[07:57.000 --> 08:02.000]  and performance-related in school for the students.\n",
            "[08:02.000 --> 08:05.000]  Because the other students that I watched were absent.\n",
            "[08:05.000 --> 08:09.000]  So I tried to ask them, and then I speak up.\n",
            "[08:09.000 --> 08:12.000]  I will not go through their privacy.\n",
            "[08:12.000 --> 08:20.000]  But they told me that they had problems, and that their experience was good.\n",
            "[08:20.000 --> 08:24.000]  So that's when I realized that family problems can have a huge impact.\n",
            "[08:24.000 --> 08:30.000]  Because it could make the attendance of Osaka students decreasingly low\n",
            "[08:30.000 --> 08:35.000]  because they don't feel the motivation or the need to go to school.\n",
            "[08:35.000 --> 08:37.000]  They are always overwhelmed with problems.\n",
            "[08:37.000 --> 08:41.000]  That's why I could say that it could affect them physically.\n",
            "[08:41.000 --> 08:43.000]  Because they don't want to go to school.\n",
            "[08:43.000 --> 08:45.000]  They don't want to do anything.\n",
            "[08:45.000 --> 08:47.000]  They don't want to go to school.\n",
            "[08:47.000 --> 08:54.000]  Emotionally, some of them are occupied with overwhelming thoughts regarding their family problems.\n",
            "[08:54.000 --> 08:56.000]  And also performance.\n",
            "[08:56.000 --> 09:01.000]  Because they can't carry out their responsibilities to the students.\n",
            "[09:01.000 --> 09:10.000]  Because their mind, heart, and physical attributes are occupied with the problems that weigh down their life.\n",
            "[09:15.000 --> 09:19.000]  Well, these family conflicts make me feel uncomfortable in my own home.\n",
            "[09:19.000 --> 09:25.000]  Because we all know that this house is our safe place, our resting place, and our solace.\n",
            "[09:25.000 --> 09:27.000]  And then, if ever there's a family conflict,\n",
            "[09:27.000 --> 09:34.000]  it's better to know that it's not your resting place, your place of refuge,\n",
            "[09:34.000 --> 09:37.000]  because it's your place of war zone.\n",
            "[09:37.000 --> 09:40.000]  So, it's better to know that it's not safe,\n",
            "[09:40.000 --> 09:44.000]  it's better to know that it's always about family conflicts.\n",
            "[09:44.000 --> 09:50.000]  And that's why maybe other people like to go outside with their friends,\n",
            "[09:50.000 --> 09:52.000]  because they don't want to spend time at home.\n",
            "[09:52.000 --> 09:56.000]  Maybe they're trying to escape the cruel reality in their life,\n",
            "[09:56.000 --> 10:02.000]  in which, at first, they used to think that their life is the safest place where they can find comfort.\n",
            "[10:02.000 --> 10:05.000]  But lately, as family conflicts enter their life,\n",
            "[10:05.000 --> 10:10.000]  they realize that maybe they don't know all about sweet stuff.\n",
            "[10:10.000 --> 10:16.000]  And maybe, one day, they'll realize what they're really looking for.\n",
            "\n",
            "Processing: Fidel Bas 5.m4a\n",
            "\n",
            "Detected language: Tagalog\n",
            "\n",
            "[00:00.000 --> 00:07.000]  Can you describe any family conflicts you have experienced at home?\n",
            "[00:07.000 --> 00:19.000]  Anong mga family conflicts ka ba?\n",
            "[00:19.000 --> 00:24.000]  Ang mga away gasing mga pamilya, na ba kayo na-experience ka nga?\n",
            "[00:25.000 --> 00:37.000]  Sa kanilang financials din, sa mga house chores, at sa mga fight na wala rasad, reasonable rasad.\n",
            "[00:37.000 --> 00:49.000]  How do these family conflicts make you feel?\n",
            "[00:49.000 --> 00:59.000]  Maka-goals na din sa school, kasi masad ganito sa inside sa school niyo.\n",
            "[01:00.000 --> 01:05.000]  Wala nang ganahan akong family na kanya.\n",
            "[01:05.000 --> 01:24.000]  Sa akong pag-i-school na ito, sa mga away kayo, tungod ka ng masyadong nag-goal.\n",
            "[01:25.000 --> 01:31.000]  Anong mga conflict ang naka-igugid ninyo?\n",
            "[01:31.000 --> 01:39.000]  Sa kanilang kwanti, akong mama, mula siyang kalayasan sa mga ito.\n",
            "[01:39.000 --> 01:47.000]  Nalain nga ako, mula ako wala sa akong sarili ito.\n",
            "[01:47.000 --> 01:55.000]  Naka-unsan niyo ang mga family conflict ninyo sa pag-focus ninyo,\n",
            "[01:55.000 --> 02:00.000]  at pag-participate ninyo sa mga activities sa iyong school?\n",
            "[02:00.000 --> 02:08.000]  Naka-unsan ninyo ang mga conflicts, mga mga experience sa balay,\n",
            "[02:08.000 --> 02:12.000]  at naka-unsan niyo ang mga conflicts ninyo sa pag-focus,\n",
            "[02:12.000 --> 02:20.000]  at pag-participate ninyo sa mga activities sa iyong school?\n",
            "[02:20.000 --> 02:27.000]  Wala nga ba ka-open ka na?\n",
            "[02:27.000 --> 02:30.000]  Yes, wala nga ako.\n",
            "[02:30.000 --> 02:45.000]  Wala nga ako mag-focus sa mga conflict na naka-unsan sa balay.\n",
            "[02:45.000 --> 02:54.000]  Wala nga ako mag-focus sa mga activities sa iyong school.\n",
            "[02:54.000 --> 03:03.000]  Wala nga ako mag-focus sa mga activities sa iyong school.\n",
            "[03:03.000 --> 03:08.000]  Wala nga ako mag-focus sa mga activities sa iyong school.\n",
            "[03:08.000 --> 03:13.000]  Wala nga ako mag-focus sa mga activities sa iyong school.\n",
            "[03:13.000 --> 03:18.000]  Wala nga ako mag-focus sa mga activities sa iyong school.\n",
            "[03:18.000 --> 03:23.000]  Wala nga ako mag-focus sa mga activities sa iyong school.\n",
            "[03:23.000 --> 03:28.000]  Wala nga ako mag-focus sa mga activities sa iyong school.\n",
            "[03:28.000 --> 03:33.000]  Wala nga ako mag-focus sa mga activities sa iyong school.\n",
            "[03:33.000 --> 03:46.000]  Wala nga ako mag-focus sa mga activities sa iyong school.\n",
            "[03:46.000 --> 04:09.000]  Wala nga ako mag-focus sa mga activities sa iyong school.\n",
            "[04:09.000 --> 04:14.000]  Ang mga mga teachers at staff sa school,\n",
            "[04:14.000 --> 04:19.000]  Ang mga mga teachers at staff sa school,\n",
            "[04:19.000 --> 04:24.000]  Ang mga mga teachers at staff sa school,\n",
            "[04:24.000 --> 04:29.000]  Ang mga mga teachers at staff sa school,\n",
            "[04:29.000 --> 04:34.000]  Ang mga mga teachers at staff sa school,\n",
            "[04:34.000 --> 04:39.000]  Ang mga mga teachers at staff sa school,\n",
            "[04:39.000 --> 04:44.000]  Ang mga mga teachers at staff sa school,\n",
            "[04:44.000 --> 04:49.000]  Ang mga mga teachers at staff sa school,\n",
            "[04:49.000 --> 04:54.000]  Ang mga mga teachers at staff sa school,\n",
            "[04:54.000 --> 04:59.000]  Ang mga mga teachers at staff sa school,\n",
            "[04:59.000 --> 05:04.000]  Ang mga mga teachers at staff sa school,\n",
            "[05:04.000 --> 05:09.000]  Ang mga mga teachers at staff sa school,\n",
            "[05:09.000 --> 05:14.000]  Ang mga mga teachers at staff sa school,\n",
            "[05:14.000 --> 05:19.000]  Ang mga mga teachers at staff sa school,\n",
            "[05:19.000 --> 05:49.000]  Ang mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga\n",
            "[05:49.000 --> 06:19.000]  mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga mga m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-17eef5390c24>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    319\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;31m# Open-Source\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m   \u001b[0;31m# fix results formatting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mdecode_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprompt_reset_since\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDecodingResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_with_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mdecode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mdecode_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mneeds_fallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msingle\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;31m# call the main sampling loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_logprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_speech_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_main_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;31m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36m_main_loop\u001b[0;34m(self, audio_features, tokens)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mlogits\u001b[0;34m(self, tokens, audio_features)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcleanup_caching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         return F.layer_norm(\n\u001b[0m\u001b[1;32m    197\u001b[0m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2541\u001b[0m             \u001b[0mlayer_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2542\u001b[0m         )\n\u001b[0;32m-> 2543\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os, subprocess\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "import whisper\n",
        "from whisper.utils import format_timestamp, get_writer, WriteTXT\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "  import tensorflow  # required in Colab to avoid protobuf compatibility issues\n",
        "except ImportError:\n",
        "  pass\n",
        "\n",
        "import torch\n",
        "\n",
        "import math\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "# select task\n",
        "\n",
        "task = \"Transcribe\" #@param [\"Transcribe\", \"Translate to English\"]\n",
        "\n",
        "task = \"transcribe\" if task == \"Transcribe\" else \"translate\"\n",
        "\n",
        "\n",
        "\n",
        "audio_file = \"Fidel Bas 5.m4a, Fidel Bas 6.m4a, Fidel Bas 7.m4a, Fidel Bas 8.m4a, Fidel Bas 9.m4a, Fidel Bas 10.m4a, Fidel Bas 11.m4a, Fidel Bas 12.m4a, Fidel Bas 13.m4a, Fidel Bas 14.m4a, Fidel Bas 15.m4a, Fidel Bas 16.m4a, Fidel Bas 17.m4a, Fidel Bas 18.m4a, Fidel Bas 19.m4a, Fidel Bas 20.m4a, Fidel Bas 21.m4a, Fidel Bas 22.m4a, Fidel Bas 23.m4a, Fidel Bas 24.m4a, Fidel Bas 25.m4a\"\n",
        "\n",
        "\n",
        "audio_files = list(map(lambda audio_path: audio_path.strip(), audio_file.split(',')))\n",
        "\n",
        "for audio_path in audio_files:\n",
        "  if not os.path.isfile(audio_path):\n",
        "    raise FileNotFoundError(audio_path)\n",
        "\n",
        "# set model\n",
        "\n",
        "use_model = \"large-v2\" #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large-v1\", \"large-v2\"]\n",
        "\n",
        "# select language\n",
        "\n",
        "language = \"Auto-Detect\" #@param [\"Auto-Detect\", \"Afrikaans\", \"Albanian\", \"Amharic\", \"Arabic\", \"Armenian\", \"Assamese\", \"Azerbaijani\", \"Bashkir\", \"Basque\", \"Belarusian\", \"Bengali\", \"Bosnian\", \"Breton\", \"Bulgarian\", \"Burmese\", \"Castilian\", \"Catalan\", \"Chinese\", \"Croatian\", \"Czech\", \"Danish\", \"Dutch\", \"English\", \"Estonian\", \"Faroese\", \"Finnish\", \"Flemish\", \"French\", \"Galician\", \"Georgian\", \"German\", \"Greek\", \"Gujarati\", \"Haitian\", \"Haitian Creole\", \"Hausa\", \"Hawaiian\", \"Hebrew\", \"Hindi\", \"Hungarian\", \"Icelandic\", \"Indonesian\", \"Italian\", \"Japanese\", \"Javanese\", \"Kannada\", \"Kazakh\", \"Khmer\", \"Korean\", \"Lao\", \"Latin\", \"Latvian\", \"Letzeburgesch\", \"Lingala\", \"Lithuanian\", \"Luxembourgish\", \"Macedonian\", \"Malagasy\", \"Malay\", \"Malayalam\", \"Maltese\", \"Maori\", \"Marathi\", \"Moldavian\", \"Moldovan\", \"Mongolian\", \"Myanmar\", \"Nepali\", \"Norwegian\", \"Nynorsk\", \"Occitan\", \"Panjabi\", \"Pashto\", \"Persian\", \"Polish\", \"Portuguese\", \"Punjabi\", \"Pushto\", \"Romanian\", \"Russian\", \"Sanskrit\", \"Serbian\", \"Shona\", \"Sindhi\", \"Sinhala\", \"Sinhalese\", \"Slovak\", \"Slovenian\", \"Somali\", \"Spanish\", \"Sundanese\", \"Swahili\", \"Swedish\", \"Tagalog\", \"Tajik\", \"Tamil\", \"Tatar\", \"Telugu\", \"Thai\", \"Tibetan\", \"Turkish\", \"Turkmen\", \"Ukrainian\", \"Urdu\", \"Uzbek\", \"Valencian\", \"Vietnamese\", \"Welsh\", \"Yiddish\", \"Yoruba\"]\n",
        "\n",
        "# other parameters\n",
        "\n",
        "prompt = \"\" #@param {type:\"string\"}\n",
        "\n",
        "coherence_preference = \"More coherence, but may repeat text\" #@param [\"More coherence, but may repeat text\", \"Less repetitions, but may have less coherence\"]\n",
        "\n",
        "api_key = '' #@param {type:\"string\"}\n",
        "\n",
        "# detect device\n",
        "\n",
        "if api_key:\n",
        "  print(\"Using API\")\n",
        "\n",
        "  from pydub import AudioSegment\n",
        "  from pydub.silence import split_on_silence\n",
        "else:\n",
        "  DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "  print(f\"Using {'GPU' if DEVICE == 'cuda' else 'CPU ‚ö†Ô∏è'}\")\n",
        "\n",
        "  # https://medium.com/analytics-vidhya/the-google-colab-system-specification-check-69d159597417\n",
        "  if DEVICE == \"cuda\":\n",
        "    !nvidia-smi -L\n",
        "  else:\n",
        "    if sys_platform == 'linux':\n",
        "      !lscpu | grep \"Model name\" | awk '{$1=$1};1'\n",
        "\n",
        "    print(\"Not using GPU can result in a very slow execution\")\n",
        "    print(\"Ensure Hardware accelerator by GPU is enabled in Google Colab: Runtime > Change runtime type\")\n",
        "\n",
        "    if use_model not in ['tiny', 'base', 'small']:\n",
        "      print(\"You may also want to try a smaller model (tiny, base, small)\")\n",
        "\n",
        "# display language\n",
        "\n",
        "WHISPER_LANGUAGES = [k.title() for k in whisper.tokenizer.TO_LANGUAGE_CODE.keys()]\n",
        "\n",
        "if language == \"Auto-Detect\":\n",
        "  language = \"detect\"\n",
        "\n",
        "if language and language != \"detect\" and language not in WHISPER_LANGUAGES:\n",
        "  print(f\"\\nLanguage '{language}' is invalid\")\n",
        "  language = \"detect\"\n",
        "\n",
        "if language and language != \"detect\":\n",
        "  print(f\"\\nLanguage: {language}\")\n",
        "\n",
        "# load model\n",
        "\n",
        "if api_key:\n",
        "  print()\n",
        "else:\n",
        "  MODELS_WITH_ENGLISH_VERSION = [\"tiny\", \"base\", \"small\", \"medium\"]\n",
        "\n",
        "  if language == \"English\" and use_model in MODELS_WITH_ENGLISH_VERSION:\n",
        "    use_model += \".en\"\n",
        "\n",
        "  print(f\"\\nLoading {use_model} model... {os.path.expanduser(f'~/.cache/whisper/{use_model}.pt')}\")\n",
        "\n",
        "  model = whisper.load_model(use_model, device=DEVICE)\n",
        "\n",
        "  print(\n",
        "      f\"Model {use_model} is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
        "      f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,d} parameters.\\n\"\n",
        "  )\n",
        "\n",
        "# set options\n",
        "\n",
        "## https://github.com/openai/whisper/blob/v20231117/whisper/transcribe.py#L37\n",
        "## https://github.com/openai/whisper/blob/v20231117/whisper/decoding.py#L81\n",
        "options = {\n",
        "    'task': task,\n",
        "    'verbose': True,\n",
        "    'fp16': True,\n",
        "    'best_of': 5,\n",
        "    'beam_size': 5,\n",
        "    'patience': None,\n",
        "    'length_penalty': None,\n",
        "    'suppress_tokens': '-1',\n",
        "    'temperature': (0.0, 0.2, 0.4, 0.6, 0.8, 1.0), # float or tuple\n",
        "    'condition_on_previous_text': coherence_preference == \"More coherence, but may repeat text\",\n",
        "    'initial_prompt': prompt or None,\n",
        "    'word_timestamps': False,\n",
        "}\n",
        "\n",
        "if api_key:\n",
        "  api_client = OpenAI(api_key=api_key)\n",
        "\n",
        "  api_supported_formats = ['mp3', 'mp4', 'mpeg', 'mpga', 'm4a', 'wav', 'webm']\n",
        "  api_max_bytes = 25 * 1024 * 1024 # 25 MB\n",
        "\n",
        "  api_transcribe = api_client.audio.transcriptions if task == 'transcribe' else api_client.audio.translations\n",
        "  api_transcribe = api_transcribe.create\n",
        "\n",
        "  api_model = 'whisper-1' # large-v2\n",
        "\n",
        "  # https://platform.openai.com/docs/api-reference/audio?lang=python\n",
        "  api_options = {\n",
        "    'response_format': 'verbose_json',\n",
        "  }\n",
        "\n",
        "  if prompt:\n",
        "    api_options['prompt'] = prompt\n",
        "\n",
        "  api_temperature = options['temperature'][0] if isinstance(options['temperature'], (tuple, list)) else options['temperature']\n",
        "\n",
        "  if isinstance(api_temperature, (float, int)):\n",
        "    api_options['temperature'] = api_temperature\n",
        "  else:\n",
        "    raise ValueError(\"Invalid temperature type, it must be a float or a tuple of floats\")\n",
        "elif DEVICE == 'cpu':\n",
        "  options['fp16'] = False\n",
        "  torch.set_num_threads(os.cpu_count())\n",
        "\n",
        "# execute task\n",
        "# !whisper \"{audio_file}\" --task {task} --model {use_model} --output_dir {output_dir} --device {DEVICE} --verbose {options['verbose']}\n",
        "\n",
        "if task == \"translate\":\n",
        "  print(\"-- TRANSLATE TO ENGLISH --\")\n",
        "else:\n",
        "  print(\"-- TRANSCRIPTION --\")\n",
        "\n",
        "results = {} # audio_path to result\n",
        "\n",
        "for audio_path in audio_files:\n",
        "  print(f\"\\nProcessing: {audio_path}\\n\")\n",
        "\n",
        "  # detect language\n",
        "  detect_language = not language or language == \"detect\"\n",
        "\n",
        "  if not detect_language:\n",
        "    options['language'] = language\n",
        "    source_language_code = whisper.tokenizer.TO_LANGUAGE_CODE.get(language.lower())\n",
        "  elif not api_key:\n",
        "    # load audio and pad/trim it to fit 30 seconds\n",
        "    audio = whisper.load_audio(audio_path)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "    # make log-Mel spectrogram and move to the same device as the model\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "    # detect the spoken language\n",
        "    _, probs = model.detect_language(mel)\n",
        "\n",
        "    source_language_code = max(probs, key=probs.get)\n",
        "    options['language'] = whisper.tokenizer.LANGUAGES[source_language_code].title()\n",
        "\n",
        "    print(f\"Detected language: {options['language']}\\n\")\n",
        "\n",
        "  # transcribe\n",
        "  if api_key:\n",
        "    # API\n",
        "    if task == \"transcribe\" and not detect_language:\n",
        "      api_options['language'] = source_language_code\n",
        "\n",
        "    source_audio_name_path, source_audio_ext = os.path.splitext(audio_path)\n",
        "    source_audio_ext = source_audio_ext[1:]\n",
        "\n",
        "    if source_audio_ext in api_supported_formats:\n",
        "      api_audio_path = audio_path\n",
        "      api_audio_ext = source_audio_ext\n",
        "    else:\n",
        "      ## convert audio file to a supported format\n",
        "      if options['verbose']:\n",
        "        print(f\"API supported formats: {','.join(api_supported_formats)}\")\n",
        "        print(f\"Converting {source_audio_ext} audio to a supported format...\")\n",
        "\n",
        "      api_audio_ext = 'mp3'\n",
        "\n",
        "      api_audio_path = f'{source_audio_name_path}.{api_audio_ext}'\n",
        "\n",
        "      subprocess.run(['ffmpeg', '-i', audio_path, api_audio_path], check=True, capture_output=True)\n",
        "\n",
        "      if options['verbose']:\n",
        "        print(api_audio_path, end='\\n\\n')\n",
        "\n",
        "    ## split audio file in chunks\n",
        "    api_audio_chunks = []\n",
        "\n",
        "    audio_bytes = os.path.getsize(api_audio_path)\n",
        "\n",
        "    if audio_bytes >= api_max_bytes:\n",
        "      if options['verbose']:\n",
        "        print(f\"Audio exceeds API maximum allowed file size.\\nSplitting audio in chunks...\")\n",
        "\n",
        "      audio_segment_file = AudioSegment.from_file(api_audio_path, api_audio_ext)\n",
        "\n",
        "      min_chunks = math.ceil(audio_bytes / (api_max_bytes / 2))\n",
        "\n",
        "      # print(f\"Min chunks: {min_chunks}\")\n",
        "\n",
        "      max_chunk_milliseconds = int(len(audio_segment_file) // min_chunks)\n",
        "\n",
        "      # print(f\"Max chunk milliseconds: {max_chunk_milliseconds}\")\n",
        "\n",
        "      def add_chunk(api_audio_chunk):\n",
        "        api_audio_chunk_path = f\"{source_audio_name_path}_{len(api_audio_chunks) + 1}.{api_audio_ext}\"\n",
        "        api_audio_chunk.export(api_audio_chunk_path, format=api_audio_ext)\n",
        "        api_audio_chunks.append(api_audio_chunk_path)\n",
        "\n",
        "      def raw_split(big_chunk):\n",
        "        subchunks = math.ceil(len(big_chunk) / max_chunk_milliseconds)\n",
        "\n",
        "        for subchunk_i in range(subchunks):\n",
        "          chunk_start = max_chunk_milliseconds * subchunk_i\n",
        "          chunk_end = min(max_chunk_milliseconds * (subchunk_i + 1), len(big_chunk))\n",
        "          add_chunk(big_chunk[chunk_start:chunk_end])\n",
        "\n",
        "      non_silent_chunks = split_on_silence(audio_segment_file,\n",
        "                                           seek_step=5, # ms\n",
        "                                           min_silence_len=1250, # ms\n",
        "                                           silence_thresh=-25, # dB\n",
        "                                           keep_silence=True) # needed to aggregate timestamps\n",
        "\n",
        "      # print(f\"Non silent chunks: {len(non_silent_chunks)}\")\n",
        "\n",
        "      current_chunk = non_silent_chunks[0] if non_silent_chunks else audio_segment_file\n",
        "\n",
        "      for next_chunk in non_silent_chunks[1:]:\n",
        "        if len(current_chunk) > max_chunk_milliseconds:\n",
        "          raw_split(current_chunk)\n",
        "          current_chunk = next_chunk\n",
        "        elif len(current_chunk) + len(next_chunk) <= max_chunk_milliseconds:\n",
        "          current_chunk += next_chunk\n",
        "        else:\n",
        "          add_chunk(current_chunk)\n",
        "          current_chunk = next_chunk\n",
        "\n",
        "      if len(current_chunk) > max_chunk_milliseconds:\n",
        "        raw_split(current_chunk)\n",
        "      else:\n",
        "        add_chunk(current_chunk)\n",
        "\n",
        "      if options['verbose']:\n",
        "        print(f'Total chunks: {len(api_audio_chunks)}\\n')\n",
        "    else:\n",
        "      api_audio_chunks.append(api_audio_path)\n",
        "\n",
        "    ## process chunks\n",
        "    result = None\n",
        "\n",
        "    for api_audio_chunk_path in api_audio_chunks:\n",
        "      ## API request\n",
        "      with open(api_audio_chunk_path, 'rb') as api_audio_file:\n",
        "        api_result = api_transcribe(model=api_model, file=api_audio_file, **api_options)\n",
        "        api_result = api_result.model_dump() # to dict\n",
        "\n",
        "      api_segments = api_result['segments']\n",
        "\n",
        "      if result:\n",
        "        ## update timestamps\n",
        "        last_segment_timestamp = result['segments'][-1]['end'] if result['segments'] else 0\n",
        "\n",
        "        for segment in api_segments:\n",
        "          segment['start'] += last_segment_timestamp\n",
        "          segment['end'] += last_segment_timestamp\n",
        "\n",
        "        ## append new segments\n",
        "        result['segments'].extend(api_segments)\n",
        "\n",
        "        if 'duration' in result:\n",
        "          result['duration'] += api_result.get('duration', 0)\n",
        "      else:\n",
        "        ## first request\n",
        "        result = api_result\n",
        "\n",
        "        if detect_language:\n",
        "          print(f\"Detected language: {result['language'].title()}\\n\")\n",
        "\n",
        "      ## display segments\n",
        "      if options['verbose']:\n",
        "        for segment in api_segments:\n",
        "          print(f\"[{format_timestamp(segment['start'])} --> {format_timestamp(segment['end'])}] {segment['text']}\")\n",
        "  else:\n",
        "    # Open-Source\n",
        "    result = whisper.transcribe(model, audio_path, **options)\n",
        "\n",
        "  # fix results formatting\n",
        "  for segment in result['segments']:\n",
        "    segment['text'] = segment['text'].strip()\n",
        "\n",
        "  result['text'] = '\\n'.join(map(lambda segment: segment['text'], result['segments']))\n",
        "\n",
        "  # set results for this audio file\n",
        "  results[audio_path] = result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTrxbUivk_h3"
      },
      "source": [
        "## [Step 4] üíæ **Save results**\n",
        "\n",
        "Run this cell to write the transcription as a file output.\n",
        "\n",
        "Results will be available in the **audio_transcription** folder in the formats selected in `output_formats`.\n",
        "\n",
        "If you don't see that folder, you may need to refresh üîÑ the Files folder.\n",
        "\n",
        "Available formats: `txt,vtt,srt,tsv,json`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "wNsrB45_lCIl",
        "outputId": "ffb6e274-25c7-4cb6-863f-8fec21f8e1b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing results...\n",
            "\n",
            "audio_transcription/Fidel Bas 1.txt\n",
            "\n",
            "audio_transcription/Fidel Bas 2.txt\n",
            "\n",
            "audio_transcription/Fidel Bas 3.txt\n",
            "\n",
            "audio_transcription/Fidel Bas 4.txt\n"
          ]
        }
      ],
      "source": [
        "# set output folder\n",
        "output_dir = \"audio_transcription\"\n",
        "\n",
        "# set output formats: https://github.com/openai/whisper/blob/v20231117/whisper/utils.py#L283\n",
        "output_formats = \"txt\" #@param [\"txt,vtt,srt,tsv,json\", \"txt,vtt,srt\", \"txt,vtt\", \"txt,srt\", \"txt\", \"vtt\", \"srt\", \"tsv\", \"json\"] {allow-input: true}\n",
        "output_formats = output_formats.split(',')\n",
        "\n",
        "from typing import TextIO\n",
        "\n",
        "class WriteText(WriteTXT):\n",
        "\n",
        "  def write_result(self, result: dict, file: TextIO, **kwargs):\n",
        "    print(result['text'], file=file, flush=True)\n",
        "\n",
        "def write_result(result, output_format, output_file_name):\n",
        "  output_format = output_format.strip()\n",
        "\n",
        "  # start captions in non-zero timestamp (some media players does not detect the first caption)\n",
        "  fix_vtt = output_format == 'vtt' and result['segments'] and result['segments'][0].get('start') == 0\n",
        "\n",
        "  if fix_vtt:\n",
        "    result['segments'][0]['start'] += 1/1000 # +1ms\n",
        "\n",
        "  # write result in the desired format\n",
        "  writer = WriteText(output_dir) if output_format == 'txt' else get_writer(output_format, output_dir)\n",
        "  writer(result, output_file_name)\n",
        "\n",
        "  if fix_vtt:\n",
        "    result['segments'][0]['start'] = 0 # reset change\n",
        "\n",
        "  output_file_path = os.path.join(output_dir, f\"{output_file_name}.{output_format}\")\n",
        "  print(output_file_path)\n",
        "\n",
        "# save results\n",
        "\n",
        "print(\"Writing results...\")\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for audio_path, result in results.items():\n",
        "  print(end='\\n')\n",
        "\n",
        "  output_file_name = os.path.splitext(os.path.basename(audio_path))[0]\n",
        "\n",
        "  for output_format in output_formats:\n",
        "    write_result(result, output_format, output_file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfkDhNMMvY8s"
      },
      "source": [
        "## [Step 5] üí¨ Translate results with DeepL (API key needed)\n",
        "\n",
        "This is an **optional** step to translate the transcription to another language using the **DeepL** API.\n",
        "\n",
        "[Get a DeepL Developer Account API Key](https://www.deepl.com/pro-api)\n",
        "\n",
        "Set the `deepl_api_key` to translate the transcription to a supported language in `deepl_target_language`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "28f7EIP-rez0"
      },
      "outputs": [],
      "source": [
        "import deepl\n",
        "\n",
        "# translation service options (DeepL Developer Account)\n",
        "\n",
        "deepl_api_key = \"\" #@param {type:\"string\"}\n",
        "\n",
        "deepl_target_language = \"\" #@param [\"\", \"Bulgarian\", \"Chinese (simplified)\", \"Czech\", \"Danish\", \"Dutch\", \"English (American)\", \"English (British)\", \"Estonian\", \"Finnish\", \"French\", \"German\", \"Greek\", \"Hungarian\", \"Indonesian\", \"Italian\", \"Japanese\", \"Korean\", \"Latvian\", \"Lithuanian\", \"Norwegian\", \"Polish\", \"Portuguese (Brazilian)\", \"Portuguese (European)\", \"Romanian\", \"Russian\", \"Slovak\", \"Slovenian\", \"Spanish\", \"Swedish\", \"Turkish\", \"Ukrainian\"]\n",
        "\n",
        "deepl_formality = \"default\" #@param [\"default\", \"formal\", \"informal\"]\n",
        "\n",
        "deepl_coherence_preference = \"Share context between lines\" #@param [\"Share context between lines\", \"Translate each line independently\"]\n",
        "deepl_coherence_preference = deepl_coherence_preference == \"Share context between lines\"\n",
        "\n",
        "if not deepl_api_key:\n",
        "  print(\"Required: deepl_api_key\")\n",
        "  print(\"Get a DeepL Developer Account API Key: https://www.deepl.com/pro-api\")\n",
        "\n",
        "if not deepl_target_language:\n",
        "  print(\"Required: deepl_target_language\")\n",
        "elif deepl_target_language == 'English':\n",
        "  deepl_target_language = \"English (British)\"\n",
        "elif deepl_target_language == 'Chinese':\n",
        "  deepl_target_language = \"Chinese (simplified)\"\n",
        "elif deepl_target_language == 'Portuguese':\n",
        "  deepl_target_language = \"Portuguese (European)\"\n",
        "\n",
        "use_deepl_translation = deepl_api_key and deepl_target_language\n",
        "\n",
        "if use_deepl_translation:\n",
        "  if deepl_formality != 'default':\n",
        "    deepl_formality = 'prefer_more' if deepl_formality == 'formal' else 'prefer_less'\n",
        "\n",
        "  translated_results = {} # audio_path to translated results\n",
        "\n",
        "  try:\n",
        "    deepl_translator = deepl.Translator(deepl_api_key)\n",
        "\n",
        "    deepl_source_languages = [lang.code.upper() for lang in deepl_translator.get_source_languages()]\n",
        "\n",
        "    deepl_target_languages_dict = deepl_translator.get_target_languages()\n",
        "    deepl_target_languages = [lang.name for lang in deepl_target_languages_dict]\n",
        "\n",
        "    deepl_target_language_code = next(lang.code for lang in deepl_target_languages_dict if lang.name == deepl_target_language).upper()\n",
        "    target_language_code = deepl_target_language_code.split('-')[0]\n",
        "\n",
        "    for audio_path, result in results.items():\n",
        "      deepl_usage = deepl_translator.get_usage()\n",
        "\n",
        "      if deepl_usage.any_limit_reached:\n",
        "        print(audio_path)\n",
        "        raise deepl.DeepLException(\"Quota for this billing period has been exceeded, message: Quota Exceeded\")\n",
        "      else:\n",
        "        print(audio_path + '\\n')\n",
        "\n",
        "      # translate results (DeepL)\n",
        "      source_language_code = whisper.tokenizer.TO_LANGUAGE_CODE.get(result['language'].lower()).upper()\n",
        "\n",
        "      if (task == 'translate' and target_language_code != 'EN') or (task == 'transcribe' and source_language_code in deepl_source_languages and source_language_code != target_language_code):\n",
        "        source_lang = source_language_code if task == 'transcribe' else None\n",
        "        translate_from = f\"from {result['language'].title()} [{source_language_code}] \" if source_lang else ''\n",
        "        print(f\"DeepL: Translate results {translate_from}to {deepl_target_language} [{deepl_target_language_code}]\\n\")\n",
        "\n",
        "        segments = result['segments']\n",
        "\n",
        "        translated_results[audio_path] = { 'text': '', 'segments': [], 'language': deepl_target_language }\n",
        "\n",
        "        # segments / request (max 128 KiB / request, so deepl_batch_requests_size is limited to around 1000)\n",
        "        deepl_batch_requests_size = 200 # 200 segments * ~100 bytes / segment = ~20 KB / request  (~15 minutes of speech)\n",
        "\n",
        "        for batch_segments in [segments[i:i + deepl_batch_requests_size] for i in range(0, len(segments), deepl_batch_requests_size)]:\n",
        "          batch_segments_text = [segment['text'] for segment in batch_segments]\n",
        "\n",
        "          if deepl_coherence_preference:\n",
        "            batch_segments_text = '<br/>'.join(batch_segments_text)\n",
        "\n",
        "          # DeepL request\n",
        "          deepl_results = deepl_translator.translate_text(\n",
        "              text=batch_segments_text,\n",
        "              source_lang=source_lang,\n",
        "              target_lang=deepl_target_language_code,\n",
        "              formality=deepl_formality,\n",
        "              split_sentences='nonewlines',\n",
        "              tag_handling='xml' if deepl_coherence_preference else None,\n",
        "              ignore_tags='br' if deepl_coherence_preference else None, # used to synchronize sentences with whisper lines but without splitting sentences in DeepL\n",
        "              outline_detection=False if deepl_coherence_preference else None\n",
        "          )\n",
        "\n",
        "          deepl_results_segments = deepl_results.text.split('<br/>') if deepl_coherence_preference else [deepl_result_segment.text for deepl_result_segment in deepl_results]\n",
        "\n",
        "          for j, translated_text in enumerate(deepl_results_segments):\n",
        "            segment = batch_segments[j]\n",
        "\n",
        "            # fix sentence formatting\n",
        "            translated_text = translated_text.lstrip(',.„ÄÇ ').rstrip()\n",
        "\n",
        "            if not deepl_coherence_preference and translated_text and translated_text[-1] in '.„ÄÇ' and segment['text'][-1] not in '.„ÄÇ':\n",
        "              translated_text = translated_text[:-1]\n",
        "\n",
        "            # add translated segments\n",
        "            translated_results[audio_path]['segments'].append(dict(id=segment['id'], start=segment['start'], end=segment['end'], text=translated_text))\n",
        "\n",
        "            if options['verbose']:\n",
        "              print(f\"[{format_timestamp(segment['start'])} --> {format_timestamp(segment['end'])}] {translated_text}\")\n",
        "\n",
        "        deepl_usage = deepl_translator.get_usage()\n",
        "\n",
        "        if deepl_usage.character.valid:\n",
        "          print(f\"\\nDeepL: Character usage: {deepl_usage.character.count} / {deepl_usage.character.limit} ({100*(deepl_usage.character.count/deepl_usage.character.limit):.2f}%)\\n\")\n",
        "      elif source_language_code == target_language_code:\n",
        "        print(f\"Nothing to translate. Results are already in {result['language']}.\")\n",
        "      elif task == 'transcribe' and source_language_code not in deepl_source_languages:\n",
        "        print(f\"DeepL: {result['language']} is not yet supported\")\n",
        "  except deepl.DeepLException as e:\n",
        "    if isinstance(e, deepl.AuthorizationException) and str(e) == \"Authorization failure, check auth_key\":\n",
        "      e = \"Authorization failure, check deepl_api_key\"\n",
        "    print(f\"\\nDeepL: [Error] {e}\\n\")\n",
        "\n",
        "  # save translated results (if any)\n",
        "\n",
        "  if translated_results:\n",
        "    print(\"Writing translated results...\")\n",
        "\n",
        "    for audio_path, translated_result in translated_results.items():\n",
        "      print(end='\\n')\n",
        "\n",
        "      translated_result['text'] = '\\n'.join(map(lambda translated_segment: translated_segment['text'], translated_result['segments']))\n",
        "\n",
        "      output_file_name = os.path.splitext(os.path.basename(audio_path))[0]\n",
        "      translated_output_file_name = f\"{output_file_name}_{deepl_target_language}\"\n",
        "\n",
        "      for output_format in output_formats:\n",
        "        write_result(translated_result, output_format, translated_output_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1j26wKsZkV6z",
        "outputId": "3d0e72cf-a2a4-4168-8f61-f8759ec4899a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "cf5167ffd3d40c187bbdee173a0e169759f2b54f4182487e61a0f59820dcd535"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}